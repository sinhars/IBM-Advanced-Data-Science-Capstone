{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0f7177c0ae9b5f17be49d5fee0218316f97afdf27c50d7946af4bb7924b3b993c",
   "display_name": "Python 3.9.1  ('.ibm_adv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f7177c0ae9b5f17be49d5fee0218316f97afdf27c50d7946af4bb7924b3b993c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# IBM Advanced Data Science Capstone Project\n",
    "## Sentiment Analysis of Amazon Customer Reviews\n",
    "### Harsh V Singh, Apr 2021"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Extract, Transform, Load (ETL)\n",
    "\n",
    "This notebook contains the comprehensive step-by-step process used for cleaning and preparing the raw data. \n",
    "\n",
    "1. The data that we are using for this project is avaiable to us in the form of two csv files (train.csv/ test.csv). We will read these files into memory and then store them in parquet files with the same name. *Spark csv reader is not able to handle commas within the quoted text of the reviews. Hence, we will first read the files into Pandas dataframes and then export them into parquet files*.\n",
    "\n",
    "2. Since the training data is quite large, we will conduct the initial data exploration and analysis on a sample set of ~10,000 rows. Once we have finalized the ETL steps, we will implement them onto the entire train and test sets.\n",
    "\n",
    "3. As part of data exploration, we will look at the distribution of heading and review text lengths and number of words. We will also look at the most common words in the review texts, both for stopwords and other words.\n",
    "\n",
    "4. As part of data processing, we will use the **nltk** package to remove stopwords, clean and tokenize the text, and lemmatize the token words. \n",
    "\n",
    "5. Our target variable will be based on a transformation of the review ratings. Ratings above 3 (i.e. 4/5) will be categorized as positive while ratings below 3 will be categorized as negative. *For the purpose of sentiment analysis, we will ignore all reviews with rating 3 as their categorization is ambiguous*.\n",
    "\n",
    "6. Lastly, we will convert the tokenized arrays into count-based sparse vectors and TFIDF-based sparse vectors which will be used as our final feature sets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pyarrow\n",
    "\n",
    "import string\n",
    "from langdetect import detect, detect_langs\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "nltk.download(\"averaged_perceptron_tagger\", quiet=True)\n",
    "ENGLISH_STOP_WORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType, StringType\n",
    "from pyspark.sql.functions import udf, rand\n",
    "conf = SparkConf().setMaster(\"local[*]\") \\\n",
    "    .setAll([(\"spark.driver.memory\", \"16g\"),\\\n",
    "            (\"spark.executor.memory\", \"8g\"), \\\n",
    "            (\"spark.driver.maxResultSize\", \"16g\")])\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "ETL_SAMPLE_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getElapsedTime(startTime, endTime):\n",
    "    elapsedTime = endTime - startTime\n",
    "    return(\"Process time = %.2f seconds.\"%(elapsedTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePandasDFToParquet(csvPath, parqPath, rawSchema, printTime=False):\n",
    "    startTime = time.time()\n",
    "    pandasDF = pd.read_csv(csvPath, header=None)\n",
    "    pandasDF.columns = rawSchema.names\n",
    "    pandasDF.to_parquet(parqPath, engine=\"pyarrow\")\n",
    "    endTime = time.time()\n",
    "    if printTime:\n",
    "        print(getElapsedTime(startTime=startTime, endTime=endTime))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSparkDFFromParquet(csvPath, parqPath, rawSchema, printTime=False):\n",
    "    parquetFile = Path(parqPath)\n",
    "    if (parquetFile.is_file() == False):\n",
    "        print(\"Parquet file not found... converting %s to parquet!\"%(csvPath))\n",
    "        savePandasDFToParquet(csvPath=csvPath, parqPath=parqPath, rawSchema=rawSchema, printTime=printTime)\n",
    "    sparkDF = spark.read.parquet(parqPath)\n",
    "    return (sparkDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawSchema = StructType([\n",
    "    StructField(\"rating\", IntegerType(), True),\n",
    "    StructField(\"review_heading\", StringType(), True),\n",
    "    StructField(\"review_text\", StringType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRaw = readSparkDFFromParquet(csvPath=\"data/train.csv\", parqPath=\"data/train.parquet\", rawSchema=rawSchema, printTime=True)\n",
    "testRaw = readSparkDFFromParquet(csvPath=\"data/test.csv\", parqPath=\"data/test.parquet\", rawSchema=rawSchema, printTime=True)\n",
    "trainRaw.show(5)\n",
    "print(\"There are %d/ %d samples in the training/ test data.\"%(trainRaw.count(), testRaw.count()))\n",
    "print(\"Sample review text: %s\"%(trainRaw.take(1)[0][\"review_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRaw = trainRaw.orderBy(rand()).limit(ETL_SAMPLE_SIZE).toPandas()\n",
    "sampleRaw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectTextLanguage(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except:\n",
    "        lang = \"error\"\n",
    "    return lang\n",
    "\n",
    "langDetectUDF = udf(lambda x: detectTextLanguage(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRaw[\"lang\"] = sampleRaw.apply(lambda x: detectTextLanguage(x[\"review_text\"]), axis=1)\n",
    "sampleRaw.drop(sampleRaw[sampleRaw[\"lang\"] != \"en\"].index, inplace=True)\n",
    "sampleRaw.drop(columns=\"lang\", inplace=True)\n",
    "\n",
    "print(\"There are %d samples left after dropping non-english language reviews.\"%(sampleRaw.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistograms(datasets, titles, figTitle, figSize=(18,6), numCols=1):\n",
    "    fig = plt.figure(figsize=figSize)\n",
    "    sns.set_theme()\n",
    "    sns.set_style(\"white\")\n",
    "    \n",
    "    numRows = math.ceil(len(datasets) / numCols)\n",
    "    for i in range(len(datasets)):\n",
    "        fig.add_subplot(numRows, numCols, i+1)\n",
    "        sns.histplot(data=datasets[i])\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.title(titles[i])\n",
    "    \n",
    "    fig.suptitle(figTitle)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistograms(\n",
    "    datasets=[\n",
    "        sampleRaw['review_heading'].str.len(),\n",
    "        sampleRaw['review_text'].str.len()],\n",
    "    titles=[\"Review Headings\", \"Review Text\"],\n",
    "    figTitle=\"Distribution of String Lengths (Sample Data)\",\n",
    "    figSize=(18,6), numCols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistograms(\n",
    "    datasets=[\n",
    "        sampleRaw['review_heading'].str.split().map(lambda x: len(x)),\n",
    "        sampleRaw['review_text'].str.split().map(lambda x: len(x))\n",
    "        ],\n",
    "    titles=[\"Review Headings\", \"Review Text\"],\n",
    "    figTitle=\"Distribution of Word Counts (Sample Data)\",\n",
    "    figSize=(18,6), numCols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSortedWordCounts(wordCounts, topN=0):\n",
    "    sortedCounts = [[k, v] for k, v in sorted(wordCounts.items(), key=lambda item: -item[1])]\n",
    "    sortedCounts = pd.DataFrame(sortedCounts, columns = [\"word\", \"count\"]) \n",
    "    if(topN > 0):\n",
    "        sortedCounts = sortedCounts.head(min(topN, sortedCounts.shape[0]))\n",
    "    return (sortedCounts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordTokensFromText(textData):\n",
    "    rawTokens = word_tokenize(textData)\n",
    "    cleanTokens = [w.lower().translate(str.maketrans('', '', string.punctuation)) for w in rawTokens]\n",
    "    wordList = [word for word in cleanTokens if word.isalpha()]\n",
    "    return (wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopWords(wordList, stopWords, topN=25):\n",
    "    stopCounts = defaultdict(int)\n",
    "    otherCounts = defaultdict(int)\n",
    "    for word in wordList:\n",
    "        if word in stopWords:\n",
    "            stopCounts[word] += 1\n",
    "        else:\n",
    "            otherCounts[word] += 1\n",
    "\n",
    "    topStopWords = getSortedWordCounts(stopCounts, topN)\n",
    "    topOtherWords = getSortedWordCounts(otherCounts, topN)\n",
    "\n",
    "    return ({\"stopWords\": topStopWords, \"otherWords\": topOtherWords})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleTokenized = sampleRaw.copy(deep=True)\n",
    "sampleTokenized[\"review_heading\"] = [getWordTokensFromText(text) for text in sampleTokenized[\"review_heading\"]]\n",
    "sampleTokenized[\"review_text\"] = [getWordTokensFromText(text) for text in sampleTokenized[\"review_text\"]]\n",
    "\n",
    "headingWords = sampleTokenized[\"review_heading\"].apply(pd.Series).stack().reset_index(drop = True).to_list()\n",
    "textWords = sampleTokenized[\"review_text\"].apply(pd.Series).stack().reset_index(drop = True).to_list()\n",
    "\n",
    "topHeadingWords = getTopWords(wordList=headingWords, stopWords=ENGLISH_STOP_WORDS, topN=25)\n",
    "topTextWords = getTopWords(wordList=textWords, stopWords=ENGLISH_STOP_WORDS, topN=25)\n",
    "\n",
    "print(\"There are %d words in the review texts of %d samples.\"%(len(textWords), sampleTokenized.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBars(datasets, titles, x, y, figTitle, figSize=(12,6), numCols=1):\n",
    "    fig = plt.figure(figsize=figSize)\n",
    "    sns.set_theme()\n",
    "    sns.set_style(\"white\")\n",
    "    \n",
    "    numRows = math.ceil(len(datasets) / numCols)\n",
    "    for i in range(len(datasets)):\n",
    "        fig.add_subplot(numRows, numCols, i+1)\n",
    "        sns.barplot(data=datasets[i], x=x, y=y)\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.title(titles[i])\n",
    "    fig.suptitle(figTitle)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBars(\n",
    "    datasets=[topHeadingWords[\"stopWords\"], topHeadingWords[\"otherWords\"], topTextWords[\"stopWords\"], topTextWords[\"otherWords\"]], \n",
    "    titles=[\"Headings - Stop Words\", \"Headings - Other Words\", \"Text - Stop Words\", \"Text - Other Words\"],\n",
    "    x=\"count\", y=\"word\", \n",
    "    figTitle=\"Count of Top Words in Headings and Review Texts (Sample Data)\", \n",
    "    figSize=(20,12), numCols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleProcessed = sampleTokenized.copy()\n",
    "sampleProcessed[\"review_content\"] = sampleProcessed[\"review_heading\"] + sampleProcessed[\"review_text\"]\n",
    "sampleProcessed.loc[sampleProcessed[\"rating\"] < 3, \"review_sentiment\"] = 0\n",
    "sampleProcessed.loc[sampleProcessed[\"rating\"] > 3, \"review_sentiment\"] = 1\n",
    "sampleProcessed.drop(columns=[\"review_heading\", \"review_text\", \"rating\"], inplace=True)\n",
    "sampleProcessed.dropna(axis=0, inplace=True)\n",
    "sampleProcessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWordsFromText(textData, stopWords):\n",
    "    relevantText = [word for word in textData if word not in stopWords]\n",
    "    return (relevantText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleProcessed[\"review_content\"] = [removeStopWordsFromText(text, ENGLISH_STOP_WORDS) for text in sampleProcessed[\"review_content\"]]\n",
    "sampleProcessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordnetPos(word):\n",
    "  tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "  tagDictionary = {\n",
    "      \"J\": wordnet.ADJ,\n",
    "      \"N\": wordnet.NOUN,\n",
    "      \"V\": wordnet.VERB,\n",
    "      \"R\": wordnet.ADV\n",
    "      }\n",
    "  return (tagDictionary.get(tag, wordnet.NOUN))\n",
    "\n",
    "def getLemmatizedText(textData, lemmatizer):\n",
    "  lemText = [lemmatizer.lemmatize(word, getWordnetPos(word)) for word in textData]\n",
    "  return (lemText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "sampleProcessed[\"review_content\"] = [getLemmatizedText(text, lemmatizer) for text in sampleProcessed[\"review_content\"]]\n",
    "endTime = time.time()\n",
    "print(getElapsedTime(startTime=startTime, endTime=endTime))\n",
    "sampleProcessed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVect = CountVectorizer()\n",
    "reviewCounts = countVect.fit_transform(sampleProcessed[\"review_content\"].apply(\" \".join))\n",
    "print(\"Review content is transformed into a %s with %s elements.\"%(type(reviewCounts), reviewCounts.shape, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(reviewCounts, sampleProcessed[\"review_sentiment\"], test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "print(\"MultinomialNB Accuracy:\", metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfVect = TfidfVectorizer()\n",
    "reviewTF = tfVect.fit_transform(sampleProcessed[\"review_content\"].apply(\" \".join))\n",
    "print(\"Review texts are transformed into a %s with %s elements.\"%(type(reviewTF), reviewTF.shape, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "trainClean = trainRaw.withColumn(\"lang\", langDetectFunc(\"review_text\"))\n",
    "trainClean = trainClean.filter(trainDF[\"lang\"] == \"en\")\n",
    "trainClean = trainClean.drop(\"lang\")\n",
    "trainClean.show(5)\n",
    "endTime = time.time()\n",
    "print(getElapsedTime(startTime=startTime, endTime=endTime))\n",
    "#print(\"There are %d samples left after dropping non-english language reviews.\"%(trainClean.count()))"
   ]
  }
 ]
}